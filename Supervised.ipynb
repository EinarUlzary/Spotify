{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 32-bit",
   "display_name": "Python 3.8.2 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "f9302fbc784ef2fba3c9d813c0c75237d03734d31e8ce593ac5b8bee5049d773"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   acousticness  artists  danceability  duration_ms  energy  explicit  \\\n0         0.995     4880         0.708     0.028442  0.1950         0   \n1         0.994    25163         0.379     0.051316  0.0135         0   \n2         0.604    26351         0.749     0.018374  0.2200         0   \n3         0.995     9738         0.781     0.032538  0.1300         0   \n4         0.990    10245         0.210     0.126450  0.2040         0   \n\n   instrumentalness  key  liveness  loudness  mode  popularity  speechiness  \\\n0             0.563   10    0.1510  0.745000     1        0.00       0.0506   \n1             0.901    8    0.0763  0.494026     1        0.00       0.0462   \n2             0.000    5    0.1190  0.627609     0        0.00       0.9290   \n3             0.887    1    0.1110  0.708887     0        0.00       0.0926   \n4             0.908   11    0.0980  0.676079     1        0.01       0.0424   \n\n      tempo  valence  year  day  month  \n0  0.485348   0.7790  1928    1      1  \n1  0.344019   0.0767  1928    1      1  \n2  0.439086   0.8800  1928    1      1  \n3  0.442470   0.7200  1928   25      9  \n4  0.254614   0.0693  1928    1      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>artists</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>explicit</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>popularity</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>valence</th>\n      <th>year</th>\n      <th>day</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.995</td>\n      <td>4880</td>\n      <td>0.708</td>\n      <td>0.028442</td>\n      <td>0.1950</td>\n      <td>0</td>\n      <td>0.563</td>\n      <td>10</td>\n      <td>0.1510</td>\n      <td>0.745000</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.0506</td>\n      <td>0.485348</td>\n      <td>0.7790</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.994</td>\n      <td>25163</td>\n      <td>0.379</td>\n      <td>0.051316</td>\n      <td>0.0135</td>\n      <td>0</td>\n      <td>0.901</td>\n      <td>8</td>\n      <td>0.0763</td>\n      <td>0.494026</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.0462</td>\n      <td>0.344019</td>\n      <td>0.0767</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.604</td>\n      <td>26351</td>\n      <td>0.749</td>\n      <td>0.018374</td>\n      <td>0.2200</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>5</td>\n      <td>0.1190</td>\n      <td>0.627609</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.9290</td>\n      <td>0.439086</td>\n      <td>0.8800</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995</td>\n      <td>9738</td>\n      <td>0.781</td>\n      <td>0.032538</td>\n      <td>0.1300</td>\n      <td>0</td>\n      <td>0.887</td>\n      <td>1</td>\n      <td>0.1110</td>\n      <td>0.708887</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.0926</td>\n      <td>0.442470</td>\n      <td>0.7200</td>\n      <td>1928</td>\n      <td>25</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.990</td>\n      <td>10245</td>\n      <td>0.210</td>\n      <td>0.126450</td>\n      <td>0.2040</td>\n      <td>0</td>\n      <td>0.908</td>\n      <td>11</td>\n      <td>0.0980</td>\n      <td>0.676079</td>\n      <td>1</td>\n      <td>0.01</td>\n      <td>0.0424</td>\n      <td>0.254614</td>\n      <td>0.0693</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "\n",
    "%store -r Spo_Clean_Data\n",
    "\n",
    "%store -r Spo_Data\n",
    "\n",
    "Spo_Clean_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Spo_Clean_Data\n",
    "X = dataset.drop('year', axis=1)\n",
    "y = dataset['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1952, 2015, 1986, ..., 1940, 1998, 2002], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 13   0   0 ...   0   0   0]\n [  0   3   3 ...   0   0   0]\n [  0   2  11 ...   0   0   0]\n ...\n [  0   0   0 ...  92  57  29]\n [  0   0   0 ...  52 121  33]\n [  0   0   0 ...  32  41 144]]\n              precision    recall  f1-score   support\n\n        1921       0.42      0.46      0.44        28\n        1922       0.33      0.20      0.25        15\n        1923       0.24      0.29      0.27        38\n        1924       0.33      0.27      0.30        45\n        1925       0.42      0.44      0.43        55\n        1926       0.66      0.64      0.65       182\n        1927       0.56      0.63      0.59       111\n        1928       0.66      0.72      0.69       232\n        1929       0.76      0.79      0.78       169\n        1930       0.39      0.36      0.38       387\n        1931       0.73      0.80      0.76       115\n        1932       0.32      0.36      0.34        87\n        1933       0.53      0.48      0.50       133\n        1934       0.55      0.56      0.56       105\n        1935       0.57      0.54      0.56       307\n        1936       0.59      0.52      0.55       237\n        1937       0.32      0.36      0.34       115\n        1938       0.39      0.46      0.42       105\n        1939       0.42      0.44      0.43       199\n        1940       0.43      0.50      0.46       367\n        1941       0.44      0.40      0.42       189\n        1942       0.61      0.64      0.62       334\n        1943       0.42      0.38      0.40       138\n        1944       0.31      0.36      0.33       138\n        1945       0.53      0.57      0.55       366\n        1946       0.49      0.42      0.46       319\n        1947       0.37      0.37      0.37       312\n        1948       0.48      0.51      0.50       370\n        1949       0.35      0.35      0.35       420\n        1950       0.31      0.30      0.30       396\n        1951       0.40      0.38      0.39       397\n        1952       0.36      0.37      0.37       419\n        1953       0.32      0.30      0.31       400\n        1954       0.25      0.24      0.25       384\n        1955       0.26      0.29      0.27       382\n        1956       0.23      0.23      0.23       386\n        1957       0.23      0.24      0.24       388\n        1958       0.25      0.25      0.25       375\n        1959       0.24      0.24      0.24       382\n        1960       0.24      0.23      0.24       426\n        1961       0.24      0.23      0.24       374\n        1962       0.20      0.19      0.19       404\n        1963       0.23      0.22      0.22       422\n        1964       0.19      0.21      0.20       396\n        1965       0.21      0.22      0.21       385\n        1966       0.24      0.22      0.23       415\n        1967       0.15      0.16      0.16       401\n        1968       0.13      0.13      0.13       399\n        1969       0.08      0.08      0.08       380\n        1970       0.10      0.11      0.10       373\n        1971       0.06      0.06      0.06       365\n        1972       0.07      0.07      0.07       408\n        1973       0.04      0.04      0.04       380\n        1974       0.05      0.05      0.05       404\n        1975       0.07      0.06      0.07       417\n        1976       0.11      0.11      0.11       426\n        1977       0.08      0.09      0.08       385\n        1978       0.10      0.11      0.11       386\n        1979       0.07      0.08      0.07       424\n        1980       0.06      0.07      0.07       385\n        1981       0.11      0.12      0.12       394\n        1982       0.09      0.08      0.09       431\n        1983       0.08      0.08      0.08       408\n        1984       0.10      0.10      0.10       403\n        1985       0.09      0.09      0.09       412\n        1986       0.08      0.07      0.07       414\n        1987       0.08      0.08      0.08       382\n        1988       0.09      0.09      0.09       396\n        1989       0.06      0.05      0.06       422\n        1990       0.06      0.07      0.07       387\n        1991       0.10      0.10      0.10       417\n        1992       0.09      0.09      0.09       409\n        1993       0.08      0.08      0.08       396\n        1994       0.06      0.06      0.06       364\n        1995       0.07      0.06      0.06       430\n        1996       0.06      0.06      0.06       419\n        1997       0.03      0.04      0.04       381\n        1998       0.05      0.05      0.05       430\n        1999       0.08      0.09      0.08       394\n        2000       0.07      0.07      0.07       402\n        2001       0.05      0.06      0.05       415\n        2002       0.06      0.06      0.06       409\n        2003       0.07      0.07      0.07       408\n        2004       0.07      0.06      0.06       432\n        2005       0.08      0.09      0.08       394\n        2006       0.06      0.06      0.06       411\n        2007       0.06      0.06      0.06       417\n        2008       0.09      0.09      0.09       407\n        2009       0.10      0.10      0.10       440\n        2010       0.11      0.11      0.11       391\n        2011       0.07      0.06      0.06       413\n        2012       0.05      0.05      0.05       405\n        2013       0.11      0.11      0.11       397\n        2014       0.09      0.10      0.10       380\n        2015       0.11      0.13      0.12       387\n        2016       0.16      0.14      0.15       402\n        2017       0.23      0.25      0.24       382\n        2018       0.24      0.24      0.24       391\n        2019       0.33      0.30      0.31       402\n        2020       0.46      0.44      0.45       326\n\n    accuracy                           0.19     33982\n   macro avg       0.23      0.23      0.23     33982\nweighted avg       0.19      0.19      0.19     33982\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Actual  Predicted\n34530     1963     1952.0\n54303     2007     1970.0\n119544    1954     1957.0\n132124    1986     1989.0\n165993    1981     1975.0\n...        ...        ...\n27979     1978     1982.0\n108428    1937     1953.0\n83427     1974     1975.0\n67859     1992     1991.0\n110456    1958     1973.0\n\n[33982 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34530</th>\n      <td>1963</td>\n      <td>1952.0</td>\n    </tr>\n    <tr>\n      <th>54303</th>\n      <td>2007</td>\n      <td>1970.0</td>\n    </tr>\n    <tr>\n      <th>119544</th>\n      <td>1954</td>\n      <td>1957.0</td>\n    </tr>\n    <tr>\n      <th>132124</th>\n      <td>1986</td>\n      <td>1989.0</td>\n    </tr>\n    <tr>\n      <th>165993</th>\n      <td>1981</td>\n      <td>1975.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27979</th>\n      <td>1978</td>\n      <td>1982.0</td>\n    </tr>\n    <tr>\n      <th>108428</th>\n      <td>1937</td>\n      <td>1953.0</td>\n    </tr>\n    <tr>\n      <th>83427</th>\n      <td>1974</td>\n      <td>1975.0</td>\n    </tr>\n    <tr>\n      <th>67859</th>\n      <td>1992</td>\n      <td>1991.0</td>\n    </tr>\n    <tr>\n      <th>110456</th>\n      <td>1958</td>\n      <td>1973.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33982 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean Absolute Error: 8.645272987660134\nMean Squared Error: 162.51334366560073\nRoot Mean Squared Error: 12.748072154863289\n"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}