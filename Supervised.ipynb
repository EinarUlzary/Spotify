{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 32-bit",
   "display_name": "Python 3.8.2 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "f9302fbc784ef2fba3c9d813c0c75237d03734d31e8ce593ac5b8bee5049d773"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   acousticness  artists  danceability  duration_ms  energy  explicit  \\\n0         0.995     4880         0.708     0.028442  0.1950         0   \n1         0.994    25163         0.379     0.051316  0.0135         0   \n2         0.604    26351         0.749     0.018374  0.2200         0   \n3         0.995     9738         0.781     0.032538  0.1300         0   \n4         0.990    10245         0.210     0.126450  0.2040         0   \n\n   instrumentalness  key  liveness  loudness  mode  popularity  speechiness  \\\n0             0.563   10    0.1510  0.745000     1        0.00       0.0506   \n1             0.901    8    0.0763  0.494026     1        0.00       0.0462   \n2             0.000    5    0.1190  0.627609     0        0.00       0.9290   \n3             0.887    1    0.1110  0.708887     0        0.00       0.0926   \n4             0.908   11    0.0980  0.676079     1        0.01       0.0424   \n\n      tempo  valence  year  Month  Day  \n0  0.485348   0.7790  1928      1    1  \n1  0.344019   0.0767  1928      1    1  \n2  0.439086   0.8800  1928      1    1  \n3  0.442470   0.7200  1928      9   25  \n4  0.254614   0.0693  1928      1    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>artists</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>explicit</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>popularity</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>valence</th>\n      <th>year</th>\n      <th>Month</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.995</td>\n      <td>4880</td>\n      <td>0.708</td>\n      <td>0.028442</td>\n      <td>0.1950</td>\n      <td>0</td>\n      <td>0.563</td>\n      <td>10</td>\n      <td>0.1510</td>\n      <td>0.745000</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.0506</td>\n      <td>0.485348</td>\n      <td>0.7790</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.994</td>\n      <td>25163</td>\n      <td>0.379</td>\n      <td>0.051316</td>\n      <td>0.0135</td>\n      <td>0</td>\n      <td>0.901</td>\n      <td>8</td>\n      <td>0.0763</td>\n      <td>0.494026</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>0.0462</td>\n      <td>0.344019</td>\n      <td>0.0767</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.604</td>\n      <td>26351</td>\n      <td>0.749</td>\n      <td>0.018374</td>\n      <td>0.2200</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>5</td>\n      <td>0.1190</td>\n      <td>0.627609</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.9290</td>\n      <td>0.439086</td>\n      <td>0.8800</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.995</td>\n      <td>9738</td>\n      <td>0.781</td>\n      <td>0.032538</td>\n      <td>0.1300</td>\n      <td>0</td>\n      <td>0.887</td>\n      <td>1</td>\n      <td>0.1110</td>\n      <td>0.708887</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>0.0926</td>\n      <td>0.442470</td>\n      <td>0.7200</td>\n      <td>1928</td>\n      <td>9</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.990</td>\n      <td>10245</td>\n      <td>0.210</td>\n      <td>0.126450</td>\n      <td>0.2040</td>\n      <td>0</td>\n      <td>0.908</td>\n      <td>11</td>\n      <td>0.0980</td>\n      <td>0.676079</td>\n      <td>1</td>\n      <td>0.01</td>\n      <td>0.0424</td>\n      <td>0.254614</td>\n      <td>0.0693</td>\n      <td>1928</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "\n",
    "%store -r Spo_Clean_Data\n",
    "\n",
    "%store -r Spo_Data\n",
    "\n",
    "Spo_Clean_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Spo_Clean_Data\n",
    "X = dataset.drop('year', axis=1)\n",
    "y = dataset['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1946, 1988, 1984, ..., 1936, 1947, 2007], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 12   1   1 ...   0   0   0]\n [  0   9   1 ...   0   0   0]\n [  0   4   9 ...   0   0   0]\n ...\n [  0   0   0 ...  73  68  33]\n [  0   0   0 ...  69 117  30]\n [  0   0   0 ...  35  45 189]]\n              precision    recall  f1-score   support\n\n        1921       0.55      0.40      0.46        30\n        1922       0.47      0.56      0.51        16\n        1923       0.21      0.28      0.24        32\n        1924       0.40      0.39      0.39        49\n        1925       0.29      0.36      0.32        39\n        1926       0.66      0.67      0.67       166\n        1927       0.58      0.62      0.60       132\n        1928       0.72      0.68      0.70       244\n        1929       0.76      0.79      0.77       173\n        1930       0.37      0.39      0.38       348\n        1931       0.78      0.78      0.78       129\n        1932       0.48      0.52      0.50       111\n        1933       0.49      0.49      0.49       114\n        1934       0.52      0.49      0.50       126\n        1935       0.54      0.54      0.54       313\n        1936       0.48      0.49      0.48       210\n        1937       0.33      0.27      0.29       123\n        1938       0.42      0.38      0.40       125\n        1939       0.41      0.40      0.40       210\n        1940       0.50      0.51      0.51       418\n        1941       0.44      0.46      0.45       184\n        1942       0.60      0.60      0.60       324\n        1943       0.38      0.34      0.36       126\n        1944       0.45      0.37      0.41       160\n        1945       0.58      0.61      0.59       406\n        1946       0.44      0.49      0.47       296\n        1947       0.40      0.42      0.41       333\n        1948       0.56      0.48      0.52       404\n        1949       0.34      0.36      0.35       379\n        1950       0.29      0.28      0.29       418\n        1951       0.36      0.38      0.37       385\n        1952       0.38      0.36      0.37       396\n        1953       0.32      0.34      0.33       381\n        1954       0.25      0.26      0.25       395\n        1955       0.28      0.26      0.27       396\n        1956       0.22      0.21      0.22       414\n        1957       0.19      0.18      0.18       409\n        1958       0.18      0.18      0.18       400\n        1959       0.17      0.18      0.17       381\n        1960       0.19      0.20      0.19       404\n        1961       0.19      0.20      0.20       403\n        1962       0.18      0.17      0.18       425\n        1963       0.22      0.22      0.22       401\n        1964       0.18      0.19      0.18       390\n        1965       0.19      0.19      0.19       376\n        1966       0.20      0.22      0.21       412\n        1967       0.11      0.11      0.11       387\n        1968       0.13      0.12      0.12       415\n        1969       0.10      0.10      0.10       389\n        1970       0.09      0.09      0.09       378\n        1971       0.11      0.10      0.10       419\n        1972       0.10      0.10      0.10       390\n        1973       0.07      0.07      0.07       386\n        1974       0.08      0.09      0.08       399\n        1975       0.05      0.05      0.05       426\n        1976       0.09      0.10      0.09       377\n        1977       0.07      0.06      0.07       415\n        1978       0.06      0.06      0.06       399\n        1979       0.10      0.09      0.09       414\n        1980       0.04      0.04      0.04       411\n        1981       0.09      0.09      0.09       414\n        1982       0.10      0.10      0.10       417\n        1983       0.11      0.12      0.12       372\n        1984       0.10      0.09      0.09       406\n        1985       0.07      0.07      0.07       407\n        1986       0.07      0.08      0.07       365\n        1987       0.09      0.09      0.09       408\n        1988       0.08      0.07      0.07       421\n        1989       0.05      0.05      0.05       389\n        1990       0.09      0.09      0.09       419\n        1991       0.09      0.08      0.09       393\n        1992       0.05      0.04      0.04       415\n        1993       0.09      0.08      0.08       425\n        1994       0.08      0.09      0.08       400\n        1995       0.06      0.06      0.06       356\n        1996       0.06      0.06      0.06       387\n        1997       0.06      0.06      0.06       428\n        1998       0.06      0.08      0.07       345\n        1999       0.06      0.06      0.06       422\n        2000       0.08      0.08      0.08       399\n        2001       0.08      0.08      0.08       401\n        2002       0.05      0.06      0.06       392\n        2003       0.07      0.07      0.07       396\n        2004       0.06      0.06      0.06       399\n        2005       0.09      0.09      0.09       410\n        2006       0.08      0.08      0.08       415\n        2007       0.06      0.06      0.06       401\n        2008       0.07      0.07      0.07       377\n        2009       0.07      0.07      0.07       360\n        2010       0.10      0.11      0.10       385\n        2011       0.08      0.09      0.08       400\n        2012       0.10      0.10      0.10       382\n        2013       0.13      0.13      0.13       405\n        2014       0.12      0.11      0.11       417\n        2015       0.12      0.12      0.12       374\n        2016       0.14      0.12      0.13       394\n        2017       0.22      0.20      0.21       419\n        2018       0.18      0.19      0.18       394\n        2019       0.28      0.31      0.29       380\n        2020       0.51      0.49      0.50       382\n\n    accuracy                           0.19     33982\n   macro avg       0.23      0.23      0.23     33982\nweighted avg       0.19      0.19      0.19     33982\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Actual  Predicted\n34530     1963     1952.0\n54303     2007     1970.0\n119544    1954     1956.0\n132124    1986     1982.0\n165993    1981     1969.0\n...        ...        ...\n27979     1978     1980.0\n108428    1937     1948.0\n83427     1974     1990.0\n67859     1992     1991.0\n110456    1958     1973.0\n\n[33982 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34530</th>\n      <td>1963</td>\n      <td>1952.0</td>\n    </tr>\n    <tr>\n      <th>54303</th>\n      <td>2007</td>\n      <td>1970.0</td>\n    </tr>\n    <tr>\n      <th>119544</th>\n      <td>1954</td>\n      <td>1956.0</td>\n    </tr>\n    <tr>\n      <th>132124</th>\n      <td>1986</td>\n      <td>1982.0</td>\n    </tr>\n    <tr>\n      <th>165993</th>\n      <td>1981</td>\n      <td>1969.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27979</th>\n      <td>1978</td>\n      <td>1980.0</td>\n    </tr>\n    <tr>\n      <th>108428</th>\n      <td>1937</td>\n      <td>1948.0</td>\n    </tr>\n    <tr>\n      <th>83427</th>\n      <td>1974</td>\n      <td>1990.0</td>\n    </tr>\n    <tr>\n      <th>67859</th>\n      <td>1992</td>\n      <td>1991.0</td>\n    </tr>\n    <tr>\n      <th>110456</th>\n      <td>1958</td>\n      <td>1973.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33982 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean Absolute Error: 8.684906715319876\nMean Squared Error: 163.05657325119833\nRoot Mean Squared Error: 12.76936072210345\n"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}